# -*- coding: utf-8 -*-
"""assignment02.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hZrDTi51nmismoVIfYsZj7KL0DSM9toc
"""

#####################################################################################################################
#   Assignment 2: Neural Network Analysis
#   This is a starter code in Python 3.6 for a neural network.
#   You need to have numpy and pandas installed before running this code.
#   You need to complete all TODO marked sections
#   You are free to modify this code in any way you want, but need to mention it
#       in the README file.
#
#####################################################################################################################


import numpy as np
import pandas as pd
from sklearn import preprocessing
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from matplotlib.pyplot import figure

class NeuralNet:
    def __init__(self, dataFile, header=True):
        self.raw_input = pd.read_csv(dataFile)

    def preprocess(self):
        processed_data = self.raw_input

        processed_data = processed_data.dropna()
        processed_data = processed_data.drop_duplicates()

        features = processed_data.iloc[:, :-1]
        label = processed_data.iloc[:, -1]

        features = preprocessing.OrdinalEncoder().fit_transform(features)
        features = preprocessing.StandardScaler(with_mean=False).fit_transform(features)
        label = preprocessing.LabelEncoder().fit_transform(label)

        #preprocess() pre splits the data into features and labels
        self.processed_features = features
        self.processed_label = label
        return 0


    def train_evaluate(self):
      #Changed below to fit preprocess
        X = self.processed_features
        y = self.processed_label
        X_train, X_test, y_train, y_test = train_test_split(
            X, y)

        # Below are the hyperparameters that you need to use for model
        #   evaluation
        activations = ['logistic', 'tanh', 'relu']
        learning_rate = [0.01, 0.1]
        max_iterations = [100, 200] # also known as epochs
        num_hidden_layers = [2, 3]
        hidden_layers = [[5,2],[7,5,2]]

        # Create the neural network and be sure to keep track of the performance
        #   metrics

        history = []
        training_table = [("Activation","Learning Rate","Max Iterations","Number of hidden layers","Training Accuracy","Test Accuracy")]

        #Sets up the plot
        figure(figsize=(8, 6), dpi=80)
        plt.xlabel('Iterations')
        plt.ylabel('Accuracy')
        plt.title('Iterations vs. Training Accuracy')
        plt.xlim([0, 200])

        #Yeah, pretty weird but it works, goes through all possible combinations of the hyperparameters
        for i in range(0,24):
          #Creates and trains the model
          classifier = MLPClassifier(solver="adam",
                                     activation=activations[int(i/8)],
                                     alpha=learning_rate[int((i%8)/4)],
                                     max_iter=max_iterations[int((i%4)/2)],
                                     hidden_layer_sizes=(hidden_layers[int(i%2)]),
                                     random_state=1,
                                     n_iter_no_change=200,
                                     early_stopping=True)#ignore these last two, they are important for validation_scores_
          classifier.fit(X_train, y_train)
          history.append(classifier.validation_scores_)

          y_train_predict = classifier.predict(X_train)
          train_accuracy = accuracy_score(y_train, y_train_predict)


          y_test_predict = classifier.predict(X_test)
          test_accuracy = accuracy_score(y_test, y_test_predict)

          Current_Data = [(activations[int(i/8)], learning_rate[int((i%8)/4)],
                           max_iterations[int((i%4)/2)],num_hidden_layers[int(i%2)],train_accuracy,test_accuracy)]
          training_table = np.vstack([training_table, Current_Data])

          plt.plot(range(1,max_iterations[int((i%4)/2)]+1), np.transpose(classifier.validation_scores_),label=activations[int(i/8)]+" " + str(learning_rate[int((i%8)/4)])+" "+
                           str(max_iterations[int((i%4)/2)])+" "+str(num_hidden_layers[int(i%2)]))

        # Plot the model history for each model in a single plot
        # model history is a plot of accuracy vs number of epochs
        # you may want to create a large sized plot to show multiple lines
        # in a same figure.
        pd.DataFrame(training_table).to_csv("file.csv")
        plt.legend(bbox_to_anchor=(1, 1))
        return 0




if __name__ == "__main__":
    neural_network = NeuralNet("https://raw.githubusercontent.com/Bondzberg/data/main/nntrainingdata.csv")
    neural_network.preprocess()
    neural_network.train_evaluate()